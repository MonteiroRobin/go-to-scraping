# üìã TODO - Go To Scraping

> Audit r√©alis√© le 2025-11-17

---

## üî¥ URGENT - √Ä faire AUJOURD'HUI

### 1. ‚úÖ Installer les d√©pendances
```bash
npm install
```
**Impact**: CRITIQUE - Le projet ne d√©marre pas sans les d√©pendances
**Temps estim√©**: 2 minutes

---

### 2. ‚úÖ Corriger la double facturation
**Fichier**: `app/api/scraping/process-job/route.ts:46`
**Probl√®me**: Les cr√©dits sont d√©duits 2 fois (dans start-job ET dans scrape-places)
**Solution**: Ajouter un flag `skipCreditDeduction` dans l'appel √† scrape-places
**Impact**: Les utilisateurs paient 2x (60 cr√©dits au lieu de 30)
**Temps estim√©**: 5 minutes

---

### 3. ‚úÖ Ajouter la facturation Grok AI
**Fichier**: `app/api/enrich-with-grok/route.ts`
**Probl√®me**: Aucun cr√©dit n'est d√©duit pour l'enrichissement Grok
**Solution**: Ajouter `consumeCredits()` avant l'appel Grok
**Impact**: Perte de revenus + risque d'abus
**Temps estim√©**: 10 minutes

```typescript
// Ajouter apr√®s la validation des param√®tres
import { CREDIT_COSTS } from "@/lib/credits-config"

const cost = CREDIT_COSTS.ENRICHMENT_GROK_PER_BUSINESS
const success = await consumeCredits(userId, cost)
if (!success) {
  return NextResponse.json(
    { error: "Cr√©dits insuffisants", requiredCredits: cost },
    { status: 402 }
  )
}
```

---

### 4. ‚úÖ Impl√©menter le refund de cr√©dits
**Fichier**: `app/api/scraping/start-job/route.ts:196`
**Probl√®me**: Si le job √©choue, les cr√©dits ne sont pas rembours√©s
**Solution**: Impl√©menter la fonction de refund
**Impact**: Utilisateurs perdent des cr√©dits injustement
**Temps estim√©**: 30 minutes

```typescript
// Remplacer le TODO par :
if (jobError) {
  console.error("[start-job] Error creating job:", jobError)

  // Refund credits
  await supabase.rpc("add_credits", {
    p_user_id: userId,
    p_amount: creditsAmount,
    p_type: "refund_job_failed",
    p_details: { error: jobError.message }
  })

  return NextResponse.json({ error: "Failed to create scraping job" }, { status: 500 })
}
```

---

### 5. ‚úÖ Supprimer lib/credits.ts
**Fichier**: `lib/credits.ts`
**Probl√®me**: Code legacy, doublon avec `lib/credits-config.ts`, variables d'env expos√©es
**Solution**: Supprimer le fichier et migrer les imports vers `credits-config.ts`
**Impact**: Confusion, bugs potentiels, faille de s√©curit√©
**Temps estim√©**: 15 minutes

**√âtapes**:
1. Rechercher tous les imports de `lib/credits.ts`
2. Les remplacer par `lib/credits-config.ts`
3. Supprimer le fichier
4. Tester que tout fonctionne

---

### 6. ‚úÖ D√©sactiver ignoreBuildErrors
**Fichier**: `next.config.mjs:4`
**Probl√®me**: Masque les erreurs TypeScript, risque de crash en production
**Solution**: D√©sactiver et corriger les erreurs TS
**Impact**: √âLEV√â - Code peut crasher en production
**Temps estim√©**: 30 minutes

```javascript
// next.config.mjs
typescript: {
  ignoreBuildErrors: false, // ‚úÖ Corriger les erreurs TS
}
```

---

### 7. ‚úÖ Optimiser les boucles SQL
**Fichier**: `app/api/scrape-places/route.ts:174-179`
**Probl√®me**: 100 requ√™tes s√©quentielles au lieu d'1 batch update
**Solution**: Utiliser `.in()` pour batch update
**Impact**: Performance (100x plus lent que n√©cessaire)
**Temps estim√©**: 5 minutes

```typescript
// Remplacer :
for (const duplicate of duplicates) {
  await supabase.from("scraped_businesses")
    .update({ last_scraped_at: new Date().toISOString() })
    .eq("place_id", duplicate.place_id)
}

// Par :
if (duplicates.length > 0) {
  await supabase
    .from("scraped_businesses")
    .update({ last_scraped_at: new Date().toISOString() })
    .in("place_id", duplicates.map(d => d.place_id))
}
```

---

### 8. ‚úÖ Corriger les variables d'environnement
**Fichiers**: `lib/supabase.ts`, `lib/credits.ts`
**Probl√®me**: Variables serveur utilis√©es c√¥t√© client (faille de s√©curit√©)
**Solution**: D√©placer toute la logique c√¥t√© serveur
**Impact**: CRITIQUE - Exposition de cl√©s sensibles
**Temps estim√©**: 1 heure

**Plan**:
1. Cr√©er des API routes pour toutes les op√©rations de cr√©dits
2. Supprimer l'acc√®s direct √† Supabase depuis le client
3. Utiliser uniquement `NEXT_PUBLIC_*` pour les variables client

---

## üü† IMPORTANT - Cette semaine

### 9. Impl√©menter rate limiting
**Impact**: Pr√©venir les abus et l'explosion des co√ªts API
**Temps estim√©**: 2 heures

```typescript
// Installer
npm install @upstash/ratelimit @upstash/redis

// Impl√©menter dans chaque API route
import { Ratelimit } from "@upstash/ratelimit"
import { Redis } from "@upstash/redis"

const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, "1 m"), // 10 req/min
})

export async function POST(req: NextRequest) {
  const ip = req.headers.get("x-forwarded-for") || "127.0.0.1"
  const { success } = await ratelimit.limit(ip)

  if (!success) {
    return NextResponse.json({ error: "Too many requests" }, { status: 429 })
  }

  // ... rest of the code
}
```

---

### 10. Ajouter tests unitaires
**Fichiers √† tester**:
- `lib/credits-config.ts` (calculs de cr√©dits)
- `lib/geocoding.ts` (parsing de villes)
- `lib/pricing-data.ts` (validation des plans)

**Framework**: Vitest ou Jest
**Temps estim√©**: 4 heures

```typescript
// tests/credits-config.test.ts
import { describe, it, expect } from 'vitest'
import { calculateScrapingCost, CREDIT_COSTS } from '@/lib/credits-config'

describe('calculateScrapingCost', () => {
  it('should return 1 credit for fresh cache', () => {
    const cost = calculateScrapingCost({ cacheStatus: 'fresh' })
    expect(cost).toBe(CREDIT_COSTS.CACHE_FRESH)
  })

  it('should return 30 credits for new scraping without contact data', () => {
    const cost = calculateScrapingCost({
      cacheStatus: 'none',
      includeContactData: false
    })
    expect(cost).toBe(CREDIT_COSTS.SCRAPING_BASIC)
  })
})
```

---

### 11. Ajouter index spatial sur Supabase
**Probl√®me**: Recherche g√©ographique lente
**Solution**: Migrer vers PostGIS
**Temps estim√©**: 3 heures

```sql
-- Migration Supabase
-- 1. Activer PostGIS
CREATE EXTENSION IF NOT EXISTS postgis;

-- 2. Ajouter colonne geography
ALTER TABLE global_businesses
ADD COLUMN location geography(POINT, 4326);

-- 3. Mettre √† jour les donn√©es existantes
UPDATE global_businesses
SET location = ST_SetSRID(ST_MakePoint(lon, lat), 4326)::geography;

-- 4. Cr√©er l'index spatial
CREATE INDEX idx_businesses_location
ON global_businesses
USING GIST (location);

-- 5. Requ√™te optimis√©e
SELECT * FROM global_businesses
WHERE ST_DWithin(
  location,
  ST_SetSRID(ST_MakePoint(:lon, :lat), 4326)::geography,
  :radius_meters
)
LIMIT 100;
```

---

### 12. Impl√©menter une vraie queue de jobs
**Probl√®me**: Fire-and-forget n'est pas fiable
**Solution**: Utiliser Inngest ou BullMQ
**Temps estim√©**: 5 heures

**Option 1: Inngest (recommand√© pour Vercel)**
```typescript
// inngest/functions.ts
import { inngest } from "./client"

export const processScrapingJob = inngest.createFunction(
  { id: "process-scraping-job" },
  { event: "scraping/job.created" },
  async ({ event, step }) => {
    const { jobId } = event.data

    const job = await step.run("fetch-job", async () => {
      return await fetchJob(jobId)
    })

    const results = await step.run("scrape-data", async () => {
      return await scrapeGooglePlaces(job.params)
    })

    await step.run("save-results", async () => {
      return await saveResults(jobId, results)
    })
  }
)
```

---

### 13. Am√©liorer le parsing des villes
**Fichier**: `lib/geocoding.ts:23`
**Probl√®me**: Regex fragile, ne g√®re que "caf√© √† Paris"
**Solution**: Parser plus robuste
**Temps estim√©**: 1 heure

```typescript
export function extractCityFromQuery(query: string): string {
  // Patterns communs
  const patterns = [
    /(?:√†|a)\s+([A-Za-z√Ä-√ø\s-]+)/i,      // "caf√© √† Paris"
    /(?:dans|sur)\s+([A-Za-z√Ä-√ø\s-]+)/i, // "restaurant dans Lyon"
    /^([A-Za-z√Ä-√ø\s-]+)$/,                 // "Paris" seul
  ]

  for (const pattern of patterns) {
    const match = query.match(pattern)
    if (match) {
      return match[1].trim()
    }
  }

  return query.trim()
}
```

---

### 14. Valider les configs avec Zod
**Fichiers**: `lib/credits-config.ts`, `lib/pricing-data.ts`
**Temps estim√©**: 2 heures

```typescript
// lib/credits-config.ts
import { z } from 'zod'

export const CreditCostsSchema = z.object({
  CACHE_FRESH: z.number().int().positive(),
  CACHE_STALE: z.number().int().positive(),
  SCRAPING_BASIC: z.number().int().positive(),
  SCRAPING_COMPLETE: z.number().int().positive(),
  ENRICHMENT_GROK_PER_BUSINESS: z.number().int().positive(),
})

// Valider au d√©marrage
CreditCostsSchema.parse(CREDIT_COSTS)
```

---

## üü° AM√âLIORATION - Ce mois

### 15. Ajouter monitoring (Sentry)
```bash
npm install @sentry/nextjs

npx @sentry/wizard@latest -i nextjs
```

---

### 16. Impl√©menter retry logic avec exponential backoff
**Fichiers**: Tous les fetch vers APIs externes
**Package**: `p-retry`

```typescript
import pRetry from 'p-retry'

const data = await pRetry(
  async () => {
    const response = await fetch(googlePlacesUrl)
    if (!response.ok) throw new Error('API error')
    return response.json()
  },
  {
    retries: 3,
    factor: 2,
    minTimeout: 1000,
    onFailedAttempt: error => {
      console.log(`Attempt ${error.attemptNumber} failed. Retrying...`)
    }
  }
)
```

---

### 17. Dashboard admin pour surveiller les cr√©dits
**Features**:
- Vue globale des cr√©dits utilis√©s par jour
- Alertes si utilisation anormale
- Stats par utilisateur
- Export des transactions

**Technologies**: Recharts + Supabase RPC

---

### 18. Documenter l'API (OpenAPI/Swagger)
**Package**: `next-swagger-doc`

```typescript
// app/api/doc/route.ts
import { createSwaggerSpec } from 'next-swagger-doc'

export async function GET() {
  const spec = createSwaggerSpec({
    apiFolder: 'app/api',
    definition: {
      openapi: '3.0.0',
      info: {
        title: 'Go To Scraping API',
        version: '1.0.0',
      },
    },
  })

  return Response.json(spec)
}
```

---

### 19. Ajouter tests E2E (Playwright)
```bash
npm install -D @playwright/test

npx playwright install
```

```typescript
// tests/e2e/scraping.spec.ts
import { test, expect } from '@playwright/test'

test('complete scraping flow', async ({ page }) => {
  await page.goto('http://localhost:3000/scraper')

  // Login
  await page.fill('[name="email"]', 'test@example.com')
  await page.click('button[type="submit"]')

  // Search
  await page.fill('[name="city"]', 'Paris')
  await page.selectOption('[name="businessType"]', 'restaurant')
  await page.click('button:has-text("Rechercher")')

  // Wait for results
  await page.waitForSelector('.results-list')

  // Verify results
  const results = await page.locator('.business-card').count()
  expect(results).toBeGreaterThan(0)
})
```

---

### 20. Migrer vers une vraie base de donn√©es vectorielle
**Pour**: Recherche s√©mantique des commerces
**Technologies**: Pinecone, Weaviate ou pgvector
**Use case**: "Trouver des restaurants romantiques √† Paris"

---

### 21. Ajouter cache Redis pour les r√©sultats
**Probl√®me**: Chaque recherche identique refait un appel DB
**Solution**: Redis avec TTL

```typescript
// lib/redis.ts
import { Redis } from '@upstash/redis'

const redis = Redis.fromEnv()

export async function getCachedSearch(key: string) {
  return await redis.get(key)
}

export async function setCachedSearch(key: string, data: any, ttl = 3600) {
  await redis.setex(key, ttl, JSON.stringify(data))
}
```

---

### 22. Optimiser les images (Next.js Image)
**V√©rifier**: Toutes les images utilisent `next/image`

---

### 23. Impl√©menter webhooks pour les clients
**Feature**: Notifier les clients quand un job est termin√©

```typescript
// app/api/scraping/process-job/route.ts
if (job.webhook_url) {
  await fetch(job.webhook_url, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      event: 'job.completed',
      jobId: job.id,
      results: businessIds,
    })
  })
}
```

---

### 24. Ajouter export automatis√© vers Google Sheets
**Package**: `googleapis`

```typescript
import { google } from 'googleapis'

const sheets = google.sheets('v4')
const auth = new google.auth.GoogleAuth({
  keyFile: 'credentials.json',
  scopes: ['https://www.googleapis.com/auth/spreadsheets'],
})

await sheets.spreadsheets.values.append({
  auth,
  spreadsheetId: 'YOUR_SHEET_ID',
  range: 'Sheet1!A1',
  valueInputOption: 'USER_ENTERED',
  resource: { values: rows },
})
```

---

### 25. Impl√©menter SSO/SAML (pour Enterprise)
**Package**: `next-auth` avec provider SAML

---

## üìä M√âTRIQUES √Ä SUIVRE

### KPIs Techniques
- [ ] Temps de r√©ponse API < 500ms (p95)
- [ ] Taux d'erreur < 1%
- [ ] Uptime > 99.9%
- [ ] Cache hit ratio > 70%

### KPIs Business
- [ ] Co√ªt moyen par scraping < 0.03‚Ç¨
- [ ] Taux de conversion free ‚Üí paid > 5%
- [ ] Churn mensuel < 5%

---

## üîß OUTILS RECOMMAND√âS

### D√©veloppement
- [ ] **ESLint** + **Prettier** (code quality)
- [ ] **Husky** (git hooks)
- [ ] **commitlint** (conventional commits)
- [ ] **Vitest** (tests unitaires)
- [ ] **Playwright** (tests E2E)

### Monitoring
- [ ] **Sentry** (error tracking)
- [ ] **LogRocket** (session replay)
- [ ] **Vercel Analytics** (web vitals)
- [ ] **Upstash QStash** (queue monitoring)

### Performance
- [ ] **Lighthouse CI** (performance tracking)
- [ ] **Bundle Analyzer** (bundle size)
- [ ] **React DevTools Profiler** (React performance)

---

## üìö DOCUMENTATION √Ä CR√âER

- [ ] **README.md** complet
- [ ] **CONTRIBUTING.md** (guide de contribution)
- [ ] **ARCHITECTURE.md** (diagrammes syst√®me)
- [ ] **API.md** (documentation API)
- [ ] **DEPLOYMENT.md** (guide de d√©ploiement)
- [ ] **CHANGELOG.md** (historique des versions)

---

## üéØ ROADMAP

### Q1 2025
- ‚úÖ Corriger tous les bugs critiques
- [ ] Impl√©menter rate limiting
- [ ] Ajouter tests (80% coverage)
- [ ] Migrer vers PostGIS
- [ ] Dashboard admin

### Q2 2025
- [ ] API publique (v1)
- [ ] Webhooks
- [ ] Export automatis√©
- [ ] Mobile app (React Native)

### Q3 2025
- [ ] Recherche s√©mantique (IA)
- [ ] Multi-langue (EN, ES, DE)
- [ ] Int√©grations tierces (Zapier, Make)

### Q4 2025
- [ ] White-label solution
- [ ] Enterprise SSO
- [ ] On-premise deployment

---

## üêõ BUGS CONNUS

- [x] Double facturation dans process-job
- [x] Enrichissement Grok gratuit
- [x] Refund manquant si job √©choue
- [x] Boucles SQL s√©quentielles
- [ ] Nominatim rate limiting non g√©r√©
- [ ] Timeout non impl√©ment√© sur Google Places API
- [ ] Pas de pagination sur les r√©sultats > 100

---

## üí° ID√âES FUTURES

- [ ] Scraping de r√©seaux sociaux (Instagram, Facebook)
- [ ] D√©tection automatique de leads (emails professionnels)
- [ ] Scoring de qualit√© des leads (IA)
- [ ] Int√©gration CRM (Salesforce, HubSpot)
- [ ] Alertes temps r√©el (nouveaux commerces)
- [ ] Analyse de sentiment des avis clients
- [ ] Comparateur de prix concurrent

---

**Derni√®re mise √† jour**: 2025-11-17
**Prochain audit**: 2025-12-17
